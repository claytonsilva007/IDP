{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green;\">**Descrição da Base de Dados \"Mall Customers\"**</span>\n",
    "\n",
    "A base de dados \"Mall Customers\" contém informações demográficas e comportamentais de clientes de um shopping. Este conjunto de dados é amplamente utilizado para análises de segmentação de clientes e inclui as seguintes colunas:\n",
    "\n",
    "- **CustomerID**: Identificação única do cliente.\n",
    "- **Gender**: Gênero do cliente (Masculino/Feminino).\n",
    "- **Age**: Idade do cliente.\n",
    "- **Annual Income (k$)**: Renda anual do cliente em milhares de dólares.\n",
    "- **Spending Score (1-100)**: Pontuação de gastos do cliente atribuída pelo shopping, com base em comportamento e hábitos de compra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Descrição do Trabalho\n",
    "\n",
    "Neste projeto, usaremos a base de dados \"Mall Customers\" para explorar técnicas de redução de dimensionalidade e clustering. Aqui estão os passos que seguiremos:\n",
    "\n",
    "1. **Preparação dos Dados**:\n",
    "   - Carregar e visualizar a base de dados.\n",
    "   - Limpar e padronizar os dados para garantir consistência e qualidade.\n",
    "\n",
    "2. **Redução de Dimensionalidade com PCA**:\n",
    "   - Aplicar Análise de Componentes Principais (PCA) para reduzir a dimensionalidade dos dados, facilitando a visualização e análise.\n",
    "\n",
    "3. **Clustering com K-Means**:\n",
    "   - Utilizar o algoritmo K-Means para agrupar os clientes em clusters com base em suas características demográficas e comportamentais.\n",
    "   - Determinar o número ideal de clusters usando o método do cotovelo (Elbow Method).\n",
    "\n",
    "4. **Visualização e Interpretação dos Resultados**:\n",
    "   - Visualizar os clusters formados após a aplicação do K-Means e do PCA.\n",
    "   - Interpretar os resultados e identificar padrões e insights sobre os diferentes segmentos de clientes.\n",
    "\n",
    "5. **Aplicações Práticas**:\n",
    "   - Explorar possíveis aplicações práticas dos resultados de clustering, como campanhas de marketing direcionadas e melhoria da experiência do cliente.\n",
    "\n",
    "Este projeto permitirá que você aplique técnicas importantes de aprendizado de máquina, como PCA e K-Means, enquanto explora um conjunto de dados real e relevante. Vamos começar a jornada de análise e segmentação de clientes!\n",
    "\n",
    "\n",
    "Link para a base de dados no Kaggle: https://www.kaggle.com/datasets/vjchoudhary7/customer-segmentation-tutorial-in-python/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\">IMPORTS E CONFIGURAÇÕES</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\">FUNÇÕES DE PROCESSAMENTO DE DADOS</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAMINHO_BASE_MALL_CUSTOMERS = \"https://raw.githubusercontent.com/claytonsilva007/IDP/refs/heads/main/ml-01/dados/mall_customer/mall_customers.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def carregar_dados(path: str):\n",
    "  dados = pd.read_csv(path)\n",
    "  return dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obter_treino_e_teste(df: pd.DataFrame, perc_treino: float = 0.8):\n",
    "    treino, teste = train_test_split(df, train_size=perc_treino ,random_state=42)\n",
    "    return treino, teste  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformar_sex_em_inteiro(df: pd.DataFrame):\n",
    "    df.Gender = df.Gender.map({'Male': 0, 'Female': 1})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\">OBTENHA E TRANSFORME OS DADOS</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregar os dados dos clientes do shopping e transforme a coluna Gender de texto para número."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = carregar_dados(path=CAMINHO_BASE_MALL_CUSTOMERS)\n",
    "df = transformar_sex_em_inteiro(df=df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sempre verifique se existem dados nulos e os tipos dos dados das colunas do dataframe com a função `info()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilize o comando `describe()` para visualizar estatísticas básicas do dataframe. Para o nosso problema atual, a escala dos números tem grande importância."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\">PADRONIZE OS DADOS</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crie um array chamado **features** contendo todas as características mais importantes. Por ora, **remova a coluna CustomerID**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df[['Age', 'AnnualIncome', 'SpendingScore']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilize a classe `StandardScaler()` e o método `fit_transform` para transformar os valores das variáveis em uma escala padrão. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = \"\"\n",
    "scaled_features = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Três motivos para padronizar dados, especialmente quando estivermos trabalhando com PCA e Clusters.\n",
    "\n",
    "**Eliminação de Unidades e Escalas Diferentes**: Dados não padronizados podem ter diferentes unidades e escalas, o que pode influenciar desproporcionalmente a análise. Por exemplo, imagine que você tem dados sobre altura (em metros) e peso (em quilos). Sem padronização, o PCA pode ser mais influenciado pelos pesos simplesmente porque os valores são numericamente maiores que as alturas.\n",
    "\n",
    "**Comparabilidade dos Componentes**: A padronização permite que cada variável contribua igualmente para a análise. Isto é especialmente importante em PCA, onde estamos interessados em entender a variação relativa entre as variáveis.\n",
    "\n",
    "**Convergência e Eficiência Computacional**: Em muitos casos, padronizar os dados pode levar a uma convergência mais rápida e eficiente dos algoritmos de PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\">REDUÇÃO DE DIMENSIONALIDADE</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduza a dimensionalidade do dataframe para 2 componentes principais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = \"\"\n",
    "principal_components = pca.\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "O que acontece quando executamos `pca.fit_transform()`?\n",
    "\n",
    "**Componentes Principais** (n_componentes=2): Eles são **combinações lineares** das variáveis originais que capturam a maior parte da variação nos dados. Em nosso caso, reduzimos a dimensionalidade para 2 componentes principais, ou seja, estamos tentando representar os dados originais em um espaço bidimensional.\n",
    "\n",
    "**Variação Explicada**: Cada componente principal explica uma certa quantidade da variância nos dados originais.  pode acessar isso com o atributo `explained_variance_ratio_` do objeto pca para entender a proporção da variância total capturada por cada componente principal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize a variância explicada utilizando o atributo `explained_variance_ratio_`. \n",
    "\n",
    "Na prática, o que desejamos ver é o percentual das informações originais representados em apenas 2 componentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize o conteúdo da variável principal_components. Utilize o slice do Python para visualizar apenas os 5 primeiros registros.\n",
    "\n",
    "Esses valores representam a contribuição das variáveis originais para cada novo componente principal. O PCA reorienta o espaço dos dados de forma que as novas direções (componentes principais) maximizem a variação dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criar um DataFrame chamado **df_pca** com os componentes principais que acabamos de calcular. \n",
    "\n",
    "O Pandas e Sklearn mantém pareada a estrutura de índices ao longo de suas operações, o que facilita a atribuição/junção entre o dataframe original (df) e o dataframe de componentes principais (df_pca) de forma simplificada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca = pd.DataFrame(data=\"\", columns=[])\n",
    "df_pca['CustomerID'] = df['CustomerID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilize a função `plot()` do pandas para gerar um gráfico de dispersão (scatter) dos componentes PC1 e PC2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<span style='color: green;'>**Por que eu devo utilizar o PCA?**</span>\n",
    "\n",
    "**Redução de Dimensionalidade**\n",
    "\n",
    "- Sozinho: Facilitar a visualização e a interpretação dos dados. Isso é útil quando você tem um grande número de variáveis e quer entender as principais tendências e padrões.\n",
    "\n",
    "- Com Outros Algoritmos: A redução de dimensionalidade pode melhorar a eficiência e a performance de outros algoritmos de machine learning. Algoritmos de clustering (como K-Means) ou classificadores (como SVM) podem se beneficiar de dados com menos dimensões, tornando o treinamento mais rápido e potencialmente mais preciso.\n",
    "\n",
    "**Remoção de Ruído**:\n",
    "\n",
    "- Sozinho: O PCA pode ajudar a eliminar variáveis redundantes e ruído nos dados, concentrando-se nas principais fontes de variabilidade. \n",
    "\n",
    "- Com Outros Algoritmos: Ao remover ruído e redundância, o PCA pode melhorar a qualidade dos dados usados em outros modelos de machine learning. \n",
    "\n",
    "**Visualização de Dados**:\n",
    "\n",
    "- Sozinho: O PCA é frequentemente usado para criar visualizações em 2D ou 3D de conjuntos de dados de alta dimensão. Essas visualizações podem revelar padrões, agrupamentos e outliers que não são visíveis em espaços de alta dimensão.\n",
    "\n",
    "- Com Outros Algoritmos: Visualizar os dados em um espaço de menor dimensão pode ajudar a entender e explicar os resultados de outros algoritmos de machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\">K-MEANS E PCA</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Selecione a quantidade de clusters utilizando o Método do Cotovelo (Elbow Method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objetivo do Elbow Plot** \n",
    "\n",
    "O objetivo do Elbow Plot é ajudar a determinar o número ideal de clusters para usar no algoritmo K-Means. Ele faz isso mostrando como a inércia muda à medida que você aumenta o número de clusters.\n",
    "\n",
    "**Inércia e Clusters**:\n",
    "\n",
    "- Inércia: É a soma das distâncias quadradas entre cada ponto de dados e o centroide do seu respectivo cluster. Em termos simples, é uma medida de quão bem os pontos de dados estão agrupados.\n",
    "\n",
    "- Número de Clusters: À medida que você aumenta o número de clusters, a inércia tende a diminuir porque os pontos de dados estão mais próximos dos centroides dos clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicie o processo criando duas variáveis, **num_clusters** e **inertia_list**, onde k será a quantidade de clustes testados e inertia_list a variável responsável por armazenar a inertia dos clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, faça o seguinte:\n",
    "- Itere a variável `num_clusters`.\n",
    "- Para cada iteração, Instancie um Objeto KMeans preencendo o atributo `n_clusters=k`, onde k é a quantidade de clusters da iteração.\n",
    "- Utilize o método fit para treinar o modelo. Para o KMeans, só preisamos passar o \"X\" (`principal_components`).\n",
    "- adicione a inertia à variável `inertia_list`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotar o gráfico do Cotovelo\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(num_clusters, inertia_list, 'bo-')\n",
    "plt.xlabel('Número de Clusters')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Método do Cotovelo para determinar o número ideal de clusters')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Aplicar K-Means com o número ideal de clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instancie um objeto chamado kmeans com o número de clusters \"ideal\" a partir do Método de Cotovelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilize o método **`fit_predict`** criar os clusters. Lembre-se de utilizar o DataFrame `principal_components`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adicionar os clusters ao DataFrame utilizando `df_pca['Cluster']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotar os clusters\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='PC1', y='PC2', hue='Cluster', data=df_pca, palette='viridis')\n",
    "plt.title('Clusters de K-Means após PCA')\n",
    "plt.xlabel('Componente Principal 1')\n",
    "plt.ylabel('Componente Principal 2')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Adicionar as características originais ao DataFrame de PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Calcular estatísticas descritivas para cada cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_stats = df_pca.groupby('Cluster').agg({\n",
    "    'Age': ['min', 'max', 'mean'],\n",
    "    'AnnualIncome': ['min', 'max', 'mean'],\n",
    "    'SpendingScore': ['min', 'max', 'mean']\n",
    "})\n",
    "\n",
    "cluster_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forma alternativa de visualizar os dados dos clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar as estatísticas descritivas\n",
    "for cluster in cluster_stats.index:\n",
    "    print(f\"Cluster {cluster}:\")\n",
    "    print(f\"Idade: {cluster_stats.loc[cluster, ('Age', 'min')]} - {cluster_stats.loc[cluster, ('Age', 'max')]}\")\n",
    "    print(f\"Renda Anual: {cluster_stats.loc[cluster, ('AnnualIncome', 'min')]}k$ - {cluster_stats.loc[cluster, ('AnnualIncome', 'max')]}k$\")\n",
    "    print(f\"Pontuação de Gastos: {cluster_stats.loc[cluster, ('SpendingScore', 'min')]} - {cluster_stats.loc[cluster, ('SpendingScore', 'max')]}\")\n",
    "    print(f\"Média de Idade: {cluster_stats.loc[cluster, ('Age', 'mean')]:.2f}\")\n",
    "    print(f\"Média de Renda Anual: {cluster_stats.loc[cluster, ('AnnualIncome', 'mean')]:.2f}k$\")\n",
    "    print(f\"Média de Pontuação de Gastos: {cluster_stats.loc[cluster, ('SpendingScore', 'mean')]:.2f}\")\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
