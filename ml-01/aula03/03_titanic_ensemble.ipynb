{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\">VISÃO GERAL DA BASE DE DADOS: Titanic</span>**\n",
    "\n",
    "Esta base de dados contém informações sobre os passageiros do Titanic, o famoso navio que afundou em 1912. Ela é amplamente utilizada para análises de sobrevivência e para entender os fatores que influenciaram a sobrevivência dos passageiros. Aqui estão algumas das variáveis incluídas:\n",
    "\n",
    "- **PassengerId**: Identificador único de cada passageiro.\n",
    "- **Survived**: Indica se o passageiro sobreviveu (1) ou não (0).\n",
    "- **Pclass**: Classe do bilhete do passageiro (1ª, 2ª, 3ª).\n",
    "- **Name**: Nome do passageiro.\n",
    "- **Sex**: Sexo do passageiro.\n",
    "- **Age**: Idade do passageiro.\n",
    "- **SibSp**: Número de irmãos/cônjuges a bordo do Titanic.\n",
    "- **Parch**: Número de pais/filhos a bordo do Titanic.\n",
    "- **Ticket**: Número do bilhete.\n",
    "- **Fare**: Tarifa paga pelo bilhete.\n",
    "- **Cabin**: Número da cabine.\n",
    "- **Embarked**: Porto de embarque (C = Cherbourg; Q = Queenstown; S = Southampton).\n",
    "\n",
    "A meta é entender como diferentes características dos passageiros e suas condições de viagem podem influenciar a probabilidade de sobrevivência no naufrágio do Titanic. Essa base de dados pode ser usada para diversas análises, como identificar padrões de sobrevivência, visualizar tendências demográficas dos passageiros e realizar previsões sobre fatores que afetaram as chances de sobrevivência.\n",
    "\n",
    "Link para a competição do Kaggle: https://www.kaggle.com/competitions/titanic/overview\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\">IMPORTS E CONFIGURAÇÕES</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, accuracy_score, precision_score, recall_score, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.linear_model import (\n",
    "    LogisticRegression,\n",
    "    RidgeClassifier,\n",
    "    SGDClassifier,\n",
    ")\n",
    "\n",
    "from sklearn.ensemble import (\n",
    "    AdaBoostClassifier, \n",
    "    BaggingClassifier, \n",
    "    ExtraTreesClassifier, \n",
    "    RandomForestClassifier, \n",
    "    StackingClassifier, \n",
    "    GradientBoostingClassifier, \n",
    "    HistGradientBoostingClassifier,\n",
    "    VotingClassifier\n",
    ")\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\">FUNÇÕES DE PROCESSAMENTO DE DADOS</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAMINHO_BASE_TREINAMENTO = 'https://raw.githubusercontent.com/claytonsilva007/IDP/refs/heads/main/ml-01/dados/titanic/train.csv'\n",
    "CAMINHO_BASE_TESTE = 'https://raw.githubusercontent.com/claytonsilva007/IDP/refs/heads/main/ml-01/dados/titanic/test.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Descrição**:\n",
    "A função `carregar_dados` tem como objetivo carregar um arquivo CSV a partir de um caminho especificado e retornar os dados em um DataFrame do pandas.\n",
    "\n",
    "**Parâmetros**:\n",
    "- `path` (str): O caminho para o arquivo CSV que será carregado.\n",
    "\n",
    "**Retorno**:\n",
    "- Retorna um DataFrame contendo os dados do arquivo CSV.\n",
    "\n",
    "**Funcionamento**:\n",
    "1. A função recebe um caminho (`path`) como string, que especifica a localização do arquivo CSV.\n",
    "2. Utiliza a função `pd.read_csv` do pandas para ler o arquivo CSV e armazenar os dados em um DataFrame.\n",
    "3. Retorna o DataFrame contendo os dados carregados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def carregar_dados(path: str):\n",
    "  dados = pd.read_csv(path)\n",
    "  return dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Descrição**:\n",
    "A função `obter_treino_e_teste` divide um DataFrame em conjuntos de treino e teste com base em uma porcentagem especificada para o treino.\n",
    "\n",
    "**Parâmetros**:\n",
    "- `df` (pd.DataFrame): O DataFrame contendo os dados a serem divididos.\n",
    "- `perc_treino` (float, opcional): A proporção dos dados a serem usados para o treino. O valor padrão é 0.8 (80%).\n",
    "\n",
    "**Retorno**:\n",
    "- Retorna duas partes do DataFrame: `treino` e `teste`.\n",
    "\n",
    "**Funcionamento**:\n",
    "1. A função recebe um DataFrame (`df`) e uma proporção (`perc_treino`) para o conjunto de treino.\n",
    "2. Utiliza a função `train_test_split` para dividir o DataFrame em conjuntos de treino e teste com a proporção especificada. A divisão é feita de forma aleatória, mas reprodutível devido ao `random_state=42`.\n",
    "3. Retorna dois DataFrames: `treino` contendo a parte de treino e `teste` contendo a parte de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obter_treino_e_teste(df: pd.DataFrame, perc_treino: float = 0.8):\n",
    "    treino, teste = train_test_split(df, train_size=perc_treino ,random_state=42)\n",
    "    return treino, teste  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Descrição**:\n",
    "A função `transformar_sex_em_inteiro` converte a coluna 'Gender' de um DataFrame, transformando os valores categóricos 'Male' e 'Female' em valores inteiros.\n",
    "\n",
    "**Parâmetros**:\n",
    "- `df` (pd.DataFrame): O DataFrame contendo a coluna 'Gender' que será transformada.\n",
    "\n",
    "**Retorno**:\n",
    "- Retorna o DataFrame com a coluna 'Gender' transformada em valores inteiros.\n",
    "\n",
    "**Funcionamento**:\n",
    "1. A função recebe um DataFrame (`df`) que contém a coluna 'Gender'.\n",
    "2. Utiliza o método `map` para converter os valores 'Male' e 'Female' em 0 e 1, respectivamente.\n",
    "3. Retorna o DataFrame com a coluna 'Gender' atualizada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformar_sex_em_inteiro(df: pd.DataFrame):\n",
    "    df.Sex = df.Sex.map({'male': 0, 'female': 1})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Descrição**:\n",
    "A função `adicionar_indicador_menor_idade` adiciona uma nova coluna chamada 'isChild' a um DataFrame. Esta coluna indica se a idade (coluna 'Age') é menor que 12 anos.\n",
    "\n",
    "**Parâmetros**:\n",
    "- `df` (pd.DataFrame): O DataFrame contendo a coluna 'Age' que será utilizada para criar o indicador.\n",
    "\n",
    "**Retorno**:\n",
    "- Retorna o DataFrame com a nova coluna 'isChild', onde o valor é 1 se a idade é menor que 18 anos e 0 caso contrário.\n",
    "\n",
    "**Funcionamento**:\n",
    "1. A função recebe um DataFrame (`df`) que contém a coluna 'Age'.\n",
    "2. Utiliza o método `map` com uma função `lambda` para criar a coluna 'isChild':\n",
    "    - Se a idade for menor que 12 (`age < 12`), a coluna 'isChild' recebe o valor 1.\n",
    "    - Caso contrário, a coluna 'isChild' recebe o valor 0.\n",
    "3. Retorna o DataFrame com a nova coluna 'isChild' adicionada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adicionar_indicador_menor_idade(df: pd.DataFrame):\n",
    "    df['isChild'] = df.Age.map(lambda age: 1 if age < 12 else 0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Descrição**:\n",
    "A função `get_pronouns` extrai os pronomes de tratamento dos nomes dos passageiros do Titanic, presentes em uma string formatada.\n",
    "\n",
    "**Parâmetros**:\n",
    "- `name` (str): Uma string contendo o nome completo do passageiro, com o sobrenome seguido por um título e o primeiro nome (ex: \"Smith, Mr. John\").\n",
    "\n",
    "**Retorno**:\n",
    "- Retorna uma string contendo o pronome de tratamento extraído do nome. Caso o formato do nome não contenha um pronome de tratamento, a função retorna \"None\".\n",
    "\n",
    "**Funcionamento**:\n",
    "1. A função recebe uma string (`name`) que contém o nome completo do passageiro.\n",
    "2. Verifica se a string contém uma vírgula (`, `) e um ponto (`.`).\n",
    "3. Se ambos estão presentes, divide a string em dois passos:\n",
    "    - Primeiramente, separa o sobrenome do restante do nome utilizando `split(\", \")`.\n",
    "    - Em seguida, separa o título do primeiro nome utilizando `split(\".\")`.\n",
    "4. Retorna a parte da string que corresponde ao título (pronome de tratamento).\n",
    "5. Se a string não contém os padrões esperados, a função retorna \"None\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pronouns(name) -> str:\n",
    "    if \", \" in name and \".\" in name:\n",
    "        return name.split(\", \")[1].split(\".\")[0]\n",
    "    return \"None\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Descrição**:\n",
    "A função `encoding_pronouns` realiza a codificação dos pronomes de tratamento presentes na coluna 'Pronouns' de um DataFrame, mapeando os valores categóricos para valores inteiros.\n",
    "\n",
    "**Parâmetros**:\n",
    "- `df` (pd.DataFrame): O DataFrame contendo a coluna 'Pronouns' que será codificada.\n",
    "\n",
    "**Retorno**:\n",
    "- Retorna o DataFrame com a coluna 'Pronouns' codificada em valores inteiros.\n",
    "\n",
    "**Funcionamento**:\n",
    "1. A função recebe um DataFrame (`df`) que contém a coluna 'Pronouns'.\n",
    "2. Utiliza o método `map` para converter os pronomes de tratamento em valores inteiros de acordo com o seguinte mapeamento:\n",
    "    - 'Mrs': 5\n",
    "    - 'Miss': 4\n",
    "    - 'Master': 3\n",
    "    - 'Other': 2\n",
    "    - 'Mr': 1\n",
    "3. Utiliza o método `fillna` para preencher valores nulos com os valores originais da coluna 'Pronouns', caso haja pronomes não incluídos no mapeamento.\n",
    "4. Retorna o DataFrame com a coluna 'Pronouns' atualizada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding_pronouns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df.Pronouns = df.Pronouns.map({'Mrs': 5, 'Miss': 4, 'Master': 3, 'Other': 2, 'Mr': 1}).fillna(df.Pronouns)\n",
    "    # df = pd.get_dummies(data=df, columns=['Pronouns'], dtype=int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Descrição**:\n",
    "A função `join_pronouns` mapeia e une diversos pronomes de tratamento em categorias padronizadas dentro de um DataFrame, substituindo pronomes específicos por categorias mais gerais.\n",
    "\n",
    "**Parâmetros**:\n",
    "- `df` (pd.DataFrame): O DataFrame contendo a coluna 'Pronouns' que será mapeada e unificada.\n",
    "\n",
    "**Retorno**:\n",
    "- Retorna o DataFrame com a coluna 'Pronouns' atualizada, contendo os pronomes padronizados.\n",
    "\n",
    "**Funcionamento**:\n",
    "1. A função recebe um DataFrame (`df`) que contém a coluna 'Pronouns'.\n",
    "2. Utiliza o método `map` para substituir os pronomes de tratamento 'Mlle', 'Ms', e 'Mme' por 'Miss' e 'Mrs', respectivamente, preenchendo valores nulos com os valores originais da coluna 'Pronouns'.\n",
    "3. Utiliza o método `map` novamente para substituir diversos outros pronomes (como 'Dr', 'Rev', 'Col', etc.) pela categoria 'Other', preenchendo valores nulos com os valores originais da coluna 'Pronouns'.\n",
    "4. Retorna o DataFrame com a coluna 'Pronouns' atualizada e padronizada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_pronouns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df['Pronouns'] = df['Pronouns'].map({'Mlle': 'Miss', 'Ms': 'Miss', 'Mme': 'Mrs'}).fillna(df['Pronouns'])\n",
    "    df.Pronouns = df['Pronouns'].map({\n",
    "        'Dr': 'Other', \n",
    "        'Rev': 'Other', \n",
    "        'Col': 'Other', \n",
    "        'Major': 'Other', \n",
    "        'Don': 'Other', \n",
    "        'Lady': 'Other', \n",
    "        'Sir': 'Other', \n",
    "        'Capt': 'Other', \n",
    "        'the Countess': 'Other', \n",
    "        'Jonkheer': 'Other',\n",
    "        'Dona': 'Other',\n",
    "    }).fillna(df['Pronouns'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Descrição**:\n",
    "A função `process_embarked` preenche valores nulos na coluna 'Embarked' de um DataFrame com o valor mais frequente e, em seguida, codifica os valores da coluna em valores numéricos.\n",
    "\n",
    "**Parâmetros**:\n",
    "- `df` (pd.DataFrame): O DataFrame contendo a coluna 'Embarked' que será processada.\n",
    "\n",
    "**Retorno**:\n",
    "- Retorna o DataFrame com a coluna 'Embarked' sem valores nulos e com os valores originais codificados em inteiros.\n",
    "\n",
    "**Funcionamento**:\n",
    "1. A função recebe um DataFrame (`df`) que contém a coluna 'Embarked'.\n",
    "2. Preenche os valores nulos na coluna 'Embarked' com o valor mais frequente (modo) da coluna.\n",
    "3. Utiliza `LabelEncoder` para transformar os valores categóricos da coluna 'Embarked' em valores numéricos.\n",
    "4. Retorna o DataFrame com a coluna 'Embarked' atualizada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_embarked(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df['Embarked'] = df['Embarked'].fillna(df['Embarked'].mode()[0])    \n",
    "    df.Embarked = LabelEncoder().fit_transform(df['Embarked'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Descrição**:\n",
    "A função `process_age` preenche valores nulos na coluna 'Age' de um DataFrame com a média das idades, calculada com base no sexo e na classe dos passageiros.\n",
    "\n",
    "**Parâmetros**:\n",
    "- `df` (pd.DataFrame): O DataFrame contendo a coluna 'Age' que será processada.\n",
    "\n",
    "**Retorno**:\n",
    "- Retorna o DataFrame com a coluna 'Age' sem valores nulos, onde os valores ausentes foram preenchidos com a média das idades para o mesmo sexo e classe.\n",
    "\n",
    "**Funcionamento**:\n",
    "1. A função recebe um DataFrame (`df`) que contém a coluna 'Age'.\n",
    "2. Utiliza o método `fillna` para preencher os valores nulos na coluna 'Age' com a média das idades dos passageiros que pertencem ao mesmo grupo de sexo (`Sex`) e classe (`Pclass`).\n",
    "3. O método `groupby` agrupa os dados por sexo e classe, e o método `transform('mean')` calcula a média da idade dentro de cada grupo.\n",
    "4. Retorna o DataFrame com a coluna 'Age' atualizada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_age(df: pd.DataFrame):\n",
    "    df['Age'] = df['Age'].fillna(df.groupby(by=['Sex', 'Pclass'])['Age'].transform('mean'))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Descrição**:\n",
    "A função `calcular_roc_auc` calcula a curva ROC e a área sob a curva (AUC) para um conjunto de valores verdadeiros e previstos.\n",
    "\n",
    "**Parâmetros**:\n",
    "- `y_true`: Lista ou array contendo os valores verdadeiros das classes.\n",
    "- `y_pred`: Lista ou array contendo as previsões do modelo.\n",
    "\n",
    "**Retorno**:\n",
    "- Retorna o valor da AUC (Área Sob a Curva ROC).\n",
    "\n",
    "**Funcionamento**:\n",
    "1. A função recebe dois parâmetros: `y_true` com os valores verdadeiros das classes e `y_pred` com as previsões do modelo.\n",
    "2. Utiliza a função `roc_curve` para calcular a curva ROC (taxa de falsos positivos `fpr` e taxa de verdadeiros positivos `tpr`).\n",
    "3. Calcula a área sob a curva (AUC) utilizando a função `auc` aplicada aos valores `fpr` e `tpr`.\n",
    "4. Retorna o valor calculado da AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_roc_auc(y_true, y_pred):\n",
    "    # Calcular a curva ROC\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
    "    \n",
    "    # Calcular a área sob a curva (AUC)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    return roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exibir_metricas_desempenho(ypred, ytrue):\n",
    "    acuracia = accuracy_score(y_pred=ypred, y_true=ytrue)\n",
    "    precisao = precision_score(y_pred=ypred, y_true=ytrue)\n",
    "    revocacao = recall_score(y_pred=ypred, y_true=ytrue)\n",
    "    roc_auc = calcular_roc_auc(y_pred=ypred, y_true=ytrue)\n",
    "\n",
    "    print(f'Acurácia: {round(acuracia, 5)}')\n",
    "    print(f'Precisão: {round(precisao, 5)}')\n",
    "    print(f'Revocação: {round(revocacao, 5)}')\n",
    "    print(f'ROC-AUC: {round(roc_auc, 5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_auc(ytrue, ypred):\n",
    "    # Gerar curva de precisão-revocação\n",
    "    precision, recall, _ = precision_recall_curve(ytrue, ypred)\n",
    "\n",
    "    plt.figure(figsize=(14, 7))\n",
    "\n",
    "    # Subplot para a curva de precisão-revocação\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(recall, precision, marker='.', label='Precision-Recall Curve')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.legend()\n",
    "\n",
    "    # Subplot para a curva ROC\n",
    "    fpr, tpr, _ = roc_curve(ytrue, ypred)\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(fpr, tpr, marker='.', label='ROC Curve')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend()\n",
    "\n",
    "    # Mostrar os gráficos\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\">OBTENHA E PROCESSE OS DADOS</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obter_dataframe_processado(path: str):\n",
    "    df = carregar_dados(path=path)\n",
    "    df = process_age(df=df)\n",
    "    df = adicionar_indicador_menor_idade(df)\n",
    "    df = transformar_sex_em_inteiro(df)\n",
    "    df['Pronouns'] = df.Name.map(get_pronouns)\n",
    "    df = join_pronouns(df)\n",
    "    df = encoding_pronouns(df=df)\n",
    "    df = process_embarked(df=df)\n",
    "    df['Fare'] = df['Fare'].fillna(df['Fare'].mean())\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>isChild</th>\n",
       "      <th>Pronouns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "\n",
       "                                                Name  Sex   Age  SibSp  Parch  \\\n",
       "0                            Braund, Mr. Owen Harris    0  22.0      1      0   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...    1  38.0      1      0   \n",
       "2                             Heikkinen, Miss. Laina    1  26.0      0      0   \n",
       "\n",
       "             Ticket     Fare Cabin  Embarked  isChild  Pronouns  \n",
       "0         A/5 21171   7.2500   NaN         2        0         1  \n",
       "1          PC 17599  71.2833   C85         0        0         5  \n",
       "2  STON/O2. 3101282   7.9250   NaN         2        0         4  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = obter_dataframe_processado(path=CAMINHO_BASE_TREINAMENTO)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span id=\"id_secao_prevendo_sobreviventes\" style=\"color:green\">SEPARE OS DADOS DE TREINO E TESTE</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reutilize o método `obter_treino_e_teste()` para dividir o dataframe em treino e teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino, teste = obter_treino_e_teste(obter_dataframe_processado(path=CAMINHO_BASE_TREINAMENTO))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_predict = ['Pclass', 'Fare', 'SibSp', 'Parch', 'Sex', 'isChild', 'Embarked', 'Age', 'Pronouns']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_treino = treino[cols_to_predict]\n",
    "y_treino = treino['Survived']\n",
    "\n",
    "x_teste = teste[cols_to_predict]\n",
    "y_teste = teste['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span id=\"id_secao_prevendo_sobreviventes\" style=\"color:green\">AVALIE DIVERSOS MODELOS EM VALIDAÇÃO CRUZADA</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crie um array de tuplas para armazenar os modelos que serão processados em validação cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Razões para Padronizar Dados em Modelos de Machine Learning\n",
    "\n",
    "1. **Consistência de Escala**\n",
    "Padronizar dados garante que todas as variáveis estejam na mesma escala, o que é crucial para algoritmos de Machine Learning que dependem da distância entre pontos de dados, como ***regressão linear e k-vizinhos mais próximos***.\n",
    "\n",
    "2. **Melhoria na Convergência**\n",
    "Algoritmos de otimização, como gradiente descendente, convergem mais rápido e com mais eficiência quando os dados são padronizados.\n",
    "\n",
    "3. **Redução de Vieses**\n",
    "A padronização ajuda a reduzir vieses que podem surgir devido a diferenças de escala, permitindo que o modelo trate todas as variáveis de forma justa.\n",
    "\n",
    "4. **Melhor Desempenho de Modelos**\n",
    "Modelos como Support Vector Machines ***(SVM) e Redes Neurais*** beneficiam-se da padronização dos dados, levando a um desempenho superior e resultados mais precisos.\n",
    "\n",
    "Conclusão\n",
    "Padronizar dados é um passo fundamental no pré-processamento de dados para Machine Learning, garantindo a consistência e eficácia dos modelos treinados. Certifique-se de incluir esse passo no seu pipeline de dados para obter melhores resultados nos seus projetos de Machine Learning.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelos que precisam de padronização\n",
    "scaled_models = [\n",
    "     ('XGBClassifier', XGBClassifier(verbosity=0, objective='binary:hinge')), \n",
    "    ('LogisticRegression', LogisticRegression()),\n",
    "    ('SGDClassifier', SGDClassifier()),\n",
    "    ('KNeighborsClassifier', KNeighborsClassifier())\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelos sem necessidade de padronização\n",
    "non_scaled_models = [\n",
    "    ('GradientBoostingClassifier', GradientBoostingClassifier()),\n",
    "    ('LGBMClassifier', LGBMClassifier(verbosity=-1)),  \n",
    "    ('RandomForestClassifier', RandomForestClassifier()),\n",
    "    ('AdaBoostClassifier', AdaBoostClassifier()),\n",
    "    ('ExtraTreesClassifier', ExtraTreesClassifier()),\n",
    "    ('HistGradientBoostingClassifier', HistGradientBoostingClassifier()),\n",
    "    ('RidgeClassifier', RidgeClassifier()),\n",
    "    ('DecisionTreeClassifier', DecisionTreeClassifier())\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = [\n",
    "    (\n",
    "        name, Pipeline(\n",
    "            [\n",
    "                ('scaler', StandardScaler()), ('classifier', model)\n",
    "            ]\n",
    "        )\n",
    "    ) for name, model in scaled_models\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models = non_scaled_models + pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Descrição**:\n",
    "A função `avaliar_modelos` realiza a validação cruzada em diversos modelos de Machine Learning e retorna a média e o desvio padrão das pontuações de precisão.\n",
    "\n",
    "**Parâmetros**:\n",
    "- `modelos`: Uma lista de tuplas contendo o nome do modelo e a instância do modelo.\n",
    "- `X`: O DataFrame contendo as características (features) do dataset.\n",
    "- `y`: A série ou DataFrame contendo os rótulos (labels) do dataset.\n",
    "- `n_splits` (int, opcional): Número de folds para a validação cruzada (padrão é 10).\n",
    "- `metric` (str, opcional): Métrica de avaliação dos modelos (padrão é 'accuracy').\n",
    "\n",
    "**Retorno**:\n",
    "- Retorna um dicionário `resultados` onde as chaves são os nomes dos modelos e os valores são dicionários contendo a média e o desvio padrão das pontuações de precisão.\n",
    "\n",
    "**Funcionamento**:\n",
    "1. A função inicializa um dicionário `resultados` para armazenar os resultados de cada modelo.\n",
    "2. Utiliza `KFold` do `sklearn` para dividir o dataset em `n_splits` folds, com embaralhamento dos dados e uma semente aleatória para reprodutibilidade.\n",
    "3. Itera sobre cada modelo na lista `modelos`:\n",
    "    - Para cada modelo, inicializa uma lista `scores` para armazenar as pontuações de cada fold.\n",
    "    - Realiza a validação cruzada sem estratificação:\n",
    "        - Divide os dados de treinamento e teste para cada fold.\n",
    "        - Treina o modelo com os dados de treinamento.\n",
    "        - Prediz os rótulos para os dados de teste.\n",
    "        - Calcula e armazena a pontuação de precisão para o fold atual.\n",
    "    - Calcula a média e o desvio padrão das pontuações de precisão e armazena no dicionário `resultados` com o nome do modelo como chave.\n",
    "4. Retorna o dicionário `resultados`.\n",
    "\n",
    "**Exemplo de Uso**:\n",
    "```python\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "modelos = [\n",
    "    ('Random Forest', RandomForestClassifier()),\n",
    "    ('Logistic Regression', LogisticRegression())\n",
    "]\n",
    "\n",
    "resultados = avaliar_modelos(modelos, X, y)\n",
    "print(resultados)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def avaliar_modelos(modelos, X, y, n_splits=10, metric='accuracy'):\n",
    "    resultados = {}\n",
    "    \n",
    "    # Divide a base de dados em 10 folds. \n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    \n",
    "    for nome, modelo in modelos:\n",
    "        scores = []\n",
    "        \n",
    "        # Realizar a validação cruzada sem estratificação\n",
    "        for train_idx, test_idx in kf.split(X):\n",
    "            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "            \n",
    "            modelo.fit(X_train, y_train)\n",
    "            y_pred = modelo.predict(X_test)\n",
    "            scores.append(accuracy_score(y_test, y_pred))\n",
    "        \n",
    "        resultados[nome] = {\n",
    "            'media': np.mean(scores),\n",
    "            'desvio_padrao': np.std(scores)\n",
    "        }\n",
    "    \n",
    "    return resultados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Descrição do Método `avaliar_modelos`\n",
    "\n",
    "O método `avaliar_modelos` realiza a validação cruzada em diversos modelos de Machine Learning e retorna a média e o desvio padrão das pontuações de precisão.\n",
    "\n",
    "### Parâmetros:\n",
    "- `modelos`: Array de tuplas contendo nomes dos modelos como chaves e instâncias dos modelos como valores.\n",
    "- `X`: O dataframe contendo as características (features) do dataset.\n",
    "- `y`: A série ou dataframe contendo os rótulos (labels) do dataset.\n",
    "- `n_splits` (opcional): Número de folds para a validação cruzada (padrão é 10).\n",
    "- `metric` (opcional): Métrica de avaliação dos modelos (padrão é 'accuracy').\n",
    "\n",
    "### Funcionamento:\n",
    "1. **Divisão da Base de Dados**:\n",
    "    - Utiliza `KFold` do `sklearn` para dividir a base de dados em `n_splits` folds, com embaralhamento dos dados e uma semente aleatória para reprodutibilidade (random_state).\n",
    "\n",
    "2. **Iteração sobre os Modelos**:\n",
    "    - Para cada modelo do array `modelos`, inicializa uma lista `scores` para armazenar as pontuações de cada fold.\n",
    "\n",
    "3. **Validação Cruzada Sem Estratificação**:\n",
    "    - Para cada fold, divide os dados de treinamento e teste.\n",
    "    - Treina o modelo com os dados de treinamento.\n",
    "    - Prediz os rótulos para os dados de teste.\n",
    "    - Calcula e armazena a pontuação de precisão para o fold atual.\n",
    "\n",
    "4. **Cálculo da Média e Desvio Padrão**:\n",
    "    - Calcula a média e o desvio padrão das pontuações de precisão para cada modelo.\n",
    "\n",
    "5. **Retorno dos Resultados**:\n",
    "    - Retorna um dicionário `resultados` contendo a média e o desvio padrão das pontuações para cada modelo.\n",
    "\n",
    "\n",
    "**Exemplo de Uso**:\n",
    "```python\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "modelos = [ \n",
    "    ('Random Forest': RandomForestClassifier()),\n",
    "    ('Logistic Regression': LogisticRegression())\n",
    "]\n",
    "\n",
    "resultados = avaliar_modelos(modelos, X, y)\n",
    "print(resultados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier: Média = 0.82493, Desvio Padrão = 0.0275\n",
      "LGBMClassifier: Média = 0.82716, Desvio Padrão = 0.0257\n",
      "RandomForestClassifier: Média = 0.82715, Desvio Padrão = 0.0149\n",
      "AdaBoostClassifier: Média = 0.81034, Desvio Padrão = 0.0162\n",
      "ExtraTreesClassifier: Média = 0.80694, Desvio Padrão = 0.0171\n",
      "HistGradientBoostingClassifier: Média = 0.83277, Desvio Padrão = 0.0209\n",
      "RidgeClassifier: Média = 0.81597, Desvio Padrão = 0.0320\n",
      "DecisionTreeClassifier: Média = 0.77104, Desvio Padrão = 0.0351\n",
      "XGBClassifier: Média = 0.78898, Desvio Padrão = 0.0324\n",
      "LogisticRegression: Média = 0.82382, Desvio Padrão = 0.0256\n",
      "SGDClassifier: Média = 0.79460, Desvio Padrão = 0.0117\n",
      "KNeighborsClassifier: Média = 0.81144, Desvio Padrão = 0.0230\n"
     ]
    }
   ],
   "source": [
    "resultados = avaliar_modelos(all_models, df[cols_to_predict], df.Survived, n_splits=5, metric='accuracy')\n",
    "\n",
    "for nome, resultado in resultados.items():\n",
    "    print(f\"{nome}: Média = {resultado['media']:.5f}, Desvio Padrão = {resultado['desvio_padrao']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\">COMBINE DIVERSOS MODELOS EM UM ENSAMBLE E FAA PREVISÕES</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8379888268156425"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criando o StackingClassifier\n",
    "stacking_model = StackingClassifier(\n",
    "    estimators=all_models,\n",
    "    final_estimator=LogisticRegression(),  # Meta-aprendiz (pode ser ajustado)\n",
    "    passthrough=False,  # Se True, inclui as features originais junto com as previsões na meta-aprendizagem\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Exemplo de treinamento\n",
    "stacking_model.fit(x_treino, y_treino)\n",
    "y_pred = stacking_model.predict(x_teste)\n",
    "accuracy_score(y_pred=y_pred, y_true=y_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\">VERSÃO RESUMIDA DO CÓDIGO</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, accuracy_score, precision_score, recall_score, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.linear_model import (\n",
    "    LogisticRegression,\n",
    "    RidgeClassifier,\n",
    "    SGDClassifier,\n",
    ")\n",
    "\n",
    "from sklearn.ensemble import (\n",
    "    AdaBoostClassifier, \n",
    "    BaggingClassifier, \n",
    "    ExtraTreesClassifier, \n",
    "    RandomForestClassifier, \n",
    "    StackingClassifier, \n",
    "    GradientBoostingClassifier, \n",
    "    HistGradientBoostingClassifier,\n",
    "    VotingClassifier\n",
    ")\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAMINHO_BASE_TREINAMENTO = 'https://raw.githubusercontent.com/claytonsilva007/IDP/refs/heads/main/ml-01/dados/titanic/train.csv'\n",
    "CAMINHO_BASE_TESTE = 'https://raw.githubusercontent.com/claytonsilva007/IDP/refs/heads/main/ml-01/dados/titanic/test.csv'\n",
    "\n",
    "\n",
    "def carregar_dados(path: str):\n",
    "  dados = pd.read_csv(path)\n",
    "  return dados\n",
    "\n",
    "\n",
    "def obter_treino_e_teste(df: pd.DataFrame, perc_treino: float = 0.8):\n",
    "    treino, teste = train_test_split(df, train_size=perc_treino ,random_state=42)\n",
    "    return treino, teste  \n",
    "\n",
    "\n",
    "def transformar_sex_em_inteiro(df: pd.DataFrame):\n",
    "    df.Sex = df.Sex.map({'male': 0, 'female': 1})\n",
    "    return df\n",
    "\n",
    "\n",
    "def adicionar_indicador_menor_idade(df: pd.DataFrame):\n",
    "    df['isChild'] = df.Age.map(lambda age: 1 if age < 12 else 0)\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_pronouns(name) -> str:\n",
    "    if \", \" in name and \".\" in name:\n",
    "        return name.split(\", \")[1].split(\".\")[0]\n",
    "    return \"None\" \n",
    "\n",
    "\n",
    "def encoding_pronouns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df.Pronouns = df.Pronouns.map({'Mrs': 5, 'Miss': 4, 'Master': 3, 'Other': 2, 'Mr': 1}).fillna(df.Pronouns)\n",
    "    # df = pd.get_dummies(data=df, columns=['Pronouns'], dtype=int)\n",
    "    return df\n",
    "\n",
    "\n",
    "def join_pronouns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df['Pronouns'] = df['Pronouns'].map({'Mlle': 'Miss', 'Ms': 'Miss', 'Mme': 'Mrs'}).fillna(df['Pronouns'])\n",
    "    df.Pronouns = df['Pronouns'].map({\n",
    "        'Dr': 'Other', \n",
    "        'Rev': 'Other', \n",
    "        'Col': 'Other', \n",
    "        'Major': 'Other', \n",
    "        'Don': 'Other', \n",
    "        'Lady': 'Other', \n",
    "        'Sir': 'Other', \n",
    "        'Capt': 'Other', \n",
    "        'the Countess': 'Other', \n",
    "        'Jonkheer': 'Other',\n",
    "        'Dona': 'Other',\n",
    "    }).fillna(df['Pronouns'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def process_embarked(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df['Embarked'] = df['Embarked'].fillna(df['Embarked'].mode()[0])    \n",
    "    df.Embarked = LabelEncoder().fit_transform(df['Embarked'])\n",
    "    return df\n",
    "\n",
    "\n",
    "def process_age(df: pd.DataFrame):\n",
    "    df['Age'] = df['Age'].fillna(df.groupby(by=['Sex', 'Pclass'])['Age'].transform('mean'))\n",
    "    return df\n",
    "\n",
    "\n",
    "def calcular_roc_auc(y_true, y_pred):\n",
    "    # Calcular a curva ROC\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
    "    \n",
    "    # Calcular a área sob a curva (AUC)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    return roc_auc\n",
    "\n",
    "\n",
    "def exibir_metricas_desempenho(ypred, ytrue):\n",
    "    acuracia = accuracy_score(y_pred=ypred, y_true=ytrue)\n",
    "    precisao = precision_score(y_pred=ypred, y_true=ytrue)\n",
    "    revocacao = recall_score(y_pred=ypred, y_true=ytrue)\n",
    "    roc_auc = calcular_roc_auc(y_pred=ypred, y_true=ytrue)\n",
    "\n",
    "    print(f'Acurácia: {round(acuracia, 5)}')\n",
    "    print(f'Precisão: {round(precisao, 5)}')\n",
    "    print(f'Revocação: {round(revocacao, 5)}')\n",
    "    print(f'ROC-AUC: {round(roc_auc, 5)}')\n",
    "\n",
    "\n",
    "def plot_roc_auc(ytrue, ypred):\n",
    "    # Gerar curva de precisão-revocação\n",
    "    precision, recall, _ = precision_recall_curve(ytrue, ypred)\n",
    "\n",
    "    plt.figure(figsize=(14, 7))\n",
    "\n",
    "    # Subplot para a curva de precisão-revocação\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(recall, precision, marker='.', label='Precision-Recall Curve')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.legend()\n",
    "\n",
    "    # Subplot para a curva ROC\n",
    "    fpr, tpr, _ = roc_curve(ytrue, ypred)\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(fpr, tpr, marker='.', label='ROC Curve')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend()\n",
    "\n",
    "    # Mostrar os gráficos\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def obter_dataframe_processado(path: str):\n",
    "    df = carregar_dados(path=path)\n",
    "    df = process_age(df=df)\n",
    "    df = adicionar_indicador_menor_idade(df)\n",
    "    df = transformar_sex_em_inteiro(df)\n",
    "    df['Pronouns'] = df.Name.map(get_pronouns)\n",
    "    df = join_pronouns(df)\n",
    "    df = encoding_pronouns(df=df)\n",
    "    df = process_embarked(df=df)\n",
    "    df['Fare'] = df['Fare'].fillna(df['Fare'].mean())\n",
    "    return df \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier: Média = 0.82491, Desvio Padrão = 0.0202\n",
      "LGBMClassifier: Média = 0.82716, Desvio Padrão = 0.0257\n",
      "RandomForestClassifier: Média = 0.82603, Desvio Padrão = 0.0134\n",
      "AdaBoostClassifier: Média = 0.81034, Desvio Padrão = 0.0162\n",
      "ExtraTreesClassifier: Média = 0.80807, Desvio Padrão = 0.0180\n",
      "HistGradientBoostingClassifier: Média = 0.83277, Desvio Padrão = 0.0209\n",
      "RidgeClassifier: Média = 0.82044, Desvio Padrão = 0.0262\n",
      "DecisionTreeClassifier: Média = 0.77665, Desvio Padrão = 0.0385\n",
      "XGBClassifier: Média = 0.79011, Desvio Padrão = 0.0301\n",
      "LogisticRegression: Média = 0.82495, Desvio Padrão = 0.0319\n",
      "SGDClassifier: Média = 0.77889, Desvio Padrão = 0.0434\n",
      "KNeighborsClassifier: Média = 0.81481, Desvio Padrão = 0.0205\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8212290502793296"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = obter_dataframe_processado(path=CAMINHO_BASE_TREINAMENTO)\n",
    "\n",
    "treino, teste = obter_treino_e_teste(obter_dataframe_processado(path=CAMINHO_BASE_TREINAMENTO))\n",
    "\n",
    "cols_to_predict = ['Pclass', 'Fare', 'SibSp', 'Parch', 'Sex', 'isChild', 'Embarked', 'Age', 'Pronouns']\n",
    "\n",
    "x_treino = treino[cols_to_predict]\n",
    "y_treino = treino['Survived']\n",
    "\n",
    "x_teste = teste[cols_to_predict]\n",
    "y_teste = teste['Survived']\n",
    "\n",
    "\n",
    "scaled_models = [\n",
    "     ('XGBClassifier', XGBClassifier(verbosity=0, objective='binary:hinge')), \n",
    "    ('LogisticRegression', LogisticRegression()),\n",
    "    ('SGDClassifier', SGDClassifier()),\n",
    "    ('KNeighborsClassifier', KNeighborsClassifier())\n",
    "]\n",
    "\n",
    "\n",
    "# Modelos sem necessidade de padronização\n",
    "non_scaled_models = [\n",
    "    ('GradientBoostingClassifier', GradientBoostingClassifier()),\n",
    "    ('LGBMClassifier', LGBMClassifier(verbosity=-1)),  \n",
    "    ('RandomForestClassifier', RandomForestClassifier()),\n",
    "    ('AdaBoostClassifier', AdaBoostClassifier()),\n",
    "    ('ExtraTreesClassifier', ExtraTreesClassifier()),\n",
    "    ('HistGradientBoostingClassifier', HistGradientBoostingClassifier()),\n",
    "    ('RidgeClassifier', RidgeClassifier()),\n",
    "    ('DecisionTreeClassifier', DecisionTreeClassifier())\n",
    "]\n",
    "\n",
    "\n",
    "pipelines = [\n",
    "    (\n",
    "        name, Pipeline(\n",
    "            [\n",
    "                ('scaler', StandardScaler()), ('classifier', model)\n",
    "            ]\n",
    "        )\n",
    "    ) for name, model in scaled_models\n",
    "]\n",
    "\n",
    "\n",
    "all_models = non_scaled_models + pipelines\n",
    "\n",
    "\n",
    "def avaliar_modelos(modelos, X, y, n_splits=10, metric='accuracy'):\n",
    "    resultados = {}\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    \n",
    "    for nome, modelo in modelos:\n",
    "        scores = []\n",
    "        for train_idx, test_idx in kf.split(X):\n",
    "            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "            \n",
    "            modelo.fit(X_train, y_train)\n",
    "            y_pred = modelo.predict(X_test)\n",
    "            scores.append(accuracy_score(y_test, y_pred))\n",
    "        \n",
    "        resultados[nome] = {\n",
    "            'media': np.mean(scores),\n",
    "            'desvio_padrao': np.std(scores)\n",
    "        }\n",
    "    \n",
    "    return resultados\n",
    "\n",
    "\n",
    "resultados = avaliar_modelos(all_models, df[cols_to_predict], df.Survived, n_splits=5, metric='accuracy')\n",
    "\n",
    "for nome, resultado in resultados.items():\n",
    "    print(f\"{nome}: Média = {resultado['media']:.5f}, Desvio Padrão = {resultado['desvio_padrao']:.4f}\")\n",
    "      \n",
    "\n",
    "stacking_model = StackingClassifier(\n",
    "    estimators=all_models,\n",
    "    final_estimator=LogisticRegression(),  # Meta-aprendiz (pode ser ajustado)\n",
    "    passthrough=False,  # Se True, inclui as features originais junto com as previsões na meta-aprendizagem\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "\n",
    "stacking_model.fit(x_treino, y_treino)\n",
    "y_pred = stacking_model.predict(x_teste)\n",
    "accuracy_score(y_pred=y_pred, y_true=y_teste)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
