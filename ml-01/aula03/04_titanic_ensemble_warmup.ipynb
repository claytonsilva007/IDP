{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\">VISÃO GERAL DA BASE DE DADOS: Titanic</span>**\n",
    "\n",
    "Esta base de dados contém informações sobre os passageiros do Titanic, o famoso navio que afundou em 1912. Ela é amplamente utilizada para análises de sobrevivência e para entender os fatores que influenciaram a sobrevivência dos passageiros. Aqui estão algumas das variáveis incluídas:\n",
    "\n",
    "- **PassengerId**: Identificador único de cada passageiro.\n",
    "- **Survived**: Indica se o passageiro sobreviveu (1) ou não (0).\n",
    "- **Pclass**: Classe do bilhete do passageiro (1ª, 2ª, 3ª).\n",
    "- **Name**: Nome do passageiro.\n",
    "- **Sex**: Sexo do passageiro.\n",
    "- **Age**: Idade do passageiro.\n",
    "- **SibSp**: Número de irmãos/cônjuges a bordo do Titanic.\n",
    "- **Parch**: Número de pais/filhos a bordo do Titanic.\n",
    "- **Ticket**: Número do bilhete.\n",
    "- **Fare**: Tarifa paga pelo bilhete.\n",
    "- **Cabin**: Número da cabine.\n",
    "- **Embarked**: Porto de embarque (C = Cherbourg; Q = Queenstown; S = Southampton).\n",
    "\n",
    "A meta é entender como diferentes características dos passageiros e suas condições de viagem podem influenciar a probabilidade de sobrevivência no naufrágio do Titanic. Essa base de dados pode ser usada para diversas análises, como identificar padrões de sobrevivência, visualizar tendências demográficas dos passageiros e realizar previsões sobre fatores que afetaram as chances de sobrevivência.\n",
    "\n",
    "Link para a competição do Kaggle: https://www.kaggle.com/competitions/titanic/overview\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\">IMPORTS E CONFIGURAÇÕES</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, accuracy_score, precision_score, recall_score, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.linear_model import (\n",
    "    LogisticRegression,\n",
    "    RidgeClassifier,\n",
    "    SGDClassifier,\n",
    ")\n",
    "\n",
    "from sklearn.ensemble import (\n",
    "    AdaBoostClassifier, \n",
    "    BaggingClassifier, \n",
    "    ExtraTreesClassifier, \n",
    "    RandomForestClassifier, \n",
    "    StackingClassifier, \n",
    "    GradientBoostingClassifier, \n",
    "    HistGradientBoostingClassifier,\n",
    "    VotingClassifier\n",
    ")\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\">FUNÇÕES DE PROCESSAMENTO DE DADOS</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAMINHO_BASE_TREINAMENTO = 'https://raw.githubusercontent.com/claytonsilva007/IDP/refs/heads/main/ml-01/dados/titanic/train.csv'\n",
    "CAMINHO_BASE_TESTE = 'https://raw.githubusercontent.com/claytonsilva007/IDP/refs/heads/main/ml-01/dados/titanic/test.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Descrição**:\n",
    "A função `carregar_dados` tem como objetivo carregar um arquivo CSV a partir de um caminho especificado e retornar os dados em um DataFrame do pandas.\n",
    "\n",
    "**Parâmetros**:\n",
    "- `path` (str): O caminho para o arquivo CSV que será carregado.\n",
    "\n",
    "**Retorno**:\n",
    "- Retorna um DataFrame contendo os dados do arquivo CSV.\n",
    "\n",
    "**Funcionamento**:\n",
    "1. A função recebe um caminho (`path`) como string, que especifica a localização do arquivo CSV.\n",
    "2. Utiliza a função `pd.read_csv` do pandas para ler o arquivo CSV e armazenar os dados em um DataFrame.\n",
    "3. Retorna o DataFrame contendo os dados carregados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def carregar_dados(path: str):\n",
    "  dados = pd.read_csv(path)\n",
    "  return dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Descrição**:\n",
    "A função `obter_treino_e_teste` divide um DataFrame em conjuntos de treino e teste com base em uma porcentagem especificada para o treino.\n",
    "\n",
    "**Parâmetros**:\n",
    "- `df` (pd.DataFrame): O DataFrame contendo os dados a serem divididos.\n",
    "- `perc_treino` (float, opcional): A proporção dos dados a serem usados para o treino. O valor padrão é 0.8 (80%).\n",
    "\n",
    "**Retorno**:\n",
    "- Retorna duas partes do DataFrame: `treino` e `teste`.\n",
    "\n",
    "**Funcionamento**:\n",
    "1. A função recebe um DataFrame (`df`) e uma proporção (`perc_treino`) para o conjunto de treino.\n",
    "2. Utiliza a função `train_test_split` para dividir o DataFrame em conjuntos de treino e teste com a proporção especificada. A divisão é feita de forma aleatória, mas reprodutível devido ao `random_state=42`.\n",
    "3. Retorna dois DataFrames: `treino` contendo a parte de treino e `teste` contendo a parte de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obter_treino_e_teste(df: pd.DataFrame, perc_treino: float = 0.8):\n",
    "    treino, teste = train_test_split(df, train_size=perc_treino ,random_state=42)\n",
    "    return treino, teste  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Descrição**:\n",
    "A função `transformar_sex_em_inteiro` converte a coluna 'Gender' de um DataFrame, transformando os valores categóricos 'Male' e 'Female' em valores inteiros.\n",
    "\n",
    "**Parâmetros**:\n",
    "- `df` (pd.DataFrame): O DataFrame contendo a coluna 'Gender' que será transformada.\n",
    "\n",
    "**Retorno**:\n",
    "- Retorna o DataFrame com a coluna 'Gender' transformada em valores inteiros.\n",
    "\n",
    "**Funcionamento**:\n",
    "1. A função recebe um DataFrame (`df`) que contém a coluna 'Gender'.\n",
    "2. Utiliza o método `map` para converter os valores 'Male' e 'Female' em 0 e 1, respectivamente.\n",
    "3. Retorna o DataFrame com a coluna 'Gender' atualizada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformar_sex_em_inteiro(df: pd.DataFrame):\n",
    "    df.Sex = df.Sex.map({'male': 0, 'female': 1})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Descrição**:\n",
    "A função `adicionar_indicador_menor_idade` adiciona uma nova coluna chamada 'isChild' a um DataFrame. Esta coluna indica se a idade (coluna 'Age') é menor que 12 anos.\n",
    "\n",
    "**Parâmetros**:\n",
    "- `df` (pd.DataFrame): O DataFrame contendo a coluna 'Age' que será utilizada para criar o indicador.\n",
    "\n",
    "**Retorno**:\n",
    "- Retorna o DataFrame com a nova coluna 'isChild', onde o valor é 1 se a idade é menor que 18 anos e 0 caso contrário.\n",
    "\n",
    "**Funcionamento**:\n",
    "1. A função recebe um DataFrame (`df`) que contém a coluna 'Age'.\n",
    "2. Utiliza o método `map` com uma função `lambda` para criar a coluna 'isChild':\n",
    "    - Se a idade for menor que 12 (`age < 12`), a coluna 'isChild' recebe o valor 1.\n",
    "    - Caso contrário, a coluna 'isChild' recebe o valor 0.\n",
    "3. Retorna o DataFrame com a nova coluna 'isChild' adicionada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adicionar_indicador_menor_idade(df: pd.DataFrame):\n",
    "    df['isChild'] = df.Age.map(lambda age: 1 if age < 12 else 0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Descrição**:\n",
    "A função `get_pronouns` extrai os pronomes de tratamento dos nomes dos passageiros do Titanic, presentes em uma string formatada.\n",
    "\n",
    "**Parâmetros**:\n",
    "- `name` (str): Uma string contendo o nome completo do passageiro, com o sobrenome seguido por um título e o primeiro nome (ex: \"Smith, Mr. John\").\n",
    "\n",
    "**Retorno**:\n",
    "- Retorna uma string contendo o pronome de tratamento extraído do nome. Caso o formato do nome não contenha um pronome de tratamento, a função retorna \"None\".\n",
    "\n",
    "**Funcionamento**:\n",
    "1. A função recebe uma string (`name`) que contém o nome completo do passageiro.\n",
    "2. Verifica se a string contém uma vírgula (`, `) e um ponto (`.`).\n",
    "3. Se ambos estão presentes, divide a string em dois passos:\n",
    "    - Primeiramente, separa o sobrenome do restante do nome utilizando `split(\", \")`.\n",
    "    - Em seguida, separa o título do primeiro nome utilizando `split(\".\")`.\n",
    "4. Retorna a parte da string que corresponde ao título (pronome de tratamento).\n",
    "5. Se a string não contém os padrões esperados, a função retorna \"None\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pronouns(name) -> str:\n",
    "    if \", \" in name and \".\" in name:\n",
    "        return name.split(\", \")[1].split(\".\")[0]\n",
    "    return \"None\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Descrição**:\n",
    "A função `encoding_pronouns` realiza a codificação dos pronomes de tratamento presentes na coluna 'Pronouns' de um DataFrame, mapeando os valores categóricos para valores inteiros.\n",
    "\n",
    "**Parâmetros**:\n",
    "- `df` (pd.DataFrame): O DataFrame contendo a coluna 'Pronouns' que será codificada.\n",
    "\n",
    "**Retorno**:\n",
    "- Retorna o DataFrame com a coluna 'Pronouns' codificada em valores inteiros.\n",
    "\n",
    "**Funcionamento**:\n",
    "1. A função recebe um DataFrame (`df`) que contém a coluna 'Pronouns'.\n",
    "2. Utiliza o método `map` para converter os pronomes de tratamento em valores inteiros de acordo com o seguinte mapeamento:\n",
    "    - 'Mrs': 5\n",
    "    - 'Miss': 4\n",
    "    - 'Master': 3\n",
    "    - 'Other': 2\n",
    "    - 'Mr': 1\n",
    "3. Utiliza o método `fillna` para preencher valores nulos com os valores originais da coluna 'Pronouns', caso haja pronomes não incluídos no mapeamento.\n",
    "4. Retorna o DataFrame com a coluna 'Pronouns' atualizada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding_pronouns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df.Pronouns = df.Pronouns.map({'Mrs': 5, 'Miss': 4, 'Master': 3, 'Other': 2, 'Mr': 1}).fillna(df.Pronouns)\n",
    "    # df = pd.get_dummies(data=df, columns=['Pronouns'], dtype=int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Descrição**:\n",
    "A função `join_pronouns` mapeia e une diversos pronomes de tratamento em categorias padronizadas dentro de um DataFrame, substituindo pronomes específicos por categorias mais gerais.\n",
    "\n",
    "**Parâmetros**:\n",
    "- `df` (pd.DataFrame): O DataFrame contendo a coluna 'Pronouns' que será mapeada e unificada.\n",
    "\n",
    "**Retorno**:\n",
    "- Retorna o DataFrame com a coluna 'Pronouns' atualizada, contendo os pronomes padronizados.\n",
    "\n",
    "**Funcionamento**:\n",
    "1. A função recebe um DataFrame (`df`) que contém a coluna 'Pronouns'.\n",
    "2. Utiliza o método `map` para substituir os pronomes de tratamento 'Mlle', 'Ms', e 'Mme' por 'Miss' e 'Mrs', respectivamente, preenchendo valores nulos com os valores originais da coluna 'Pronouns'.\n",
    "3. Utiliza o método `map` novamente para substituir diversos outros pronomes (como 'Dr', 'Rev', 'Col', etc.) pela categoria 'Other', preenchendo valores nulos com os valores originais da coluna 'Pronouns'.\n",
    "4. Retorna o DataFrame com a coluna 'Pronouns' atualizada e padronizada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_pronouns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df['Pronouns'] = df['Pronouns'].map({'Mlle': 'Miss', 'Ms': 'Miss', 'Mme': 'Mrs'}).fillna(df['Pronouns'])\n",
    "    df.Pronouns = df['Pronouns'].map({\n",
    "        'Dr': 'Other', \n",
    "        'Rev': 'Other', \n",
    "        'Col': 'Other', \n",
    "        'Major': 'Other', \n",
    "        'Don': 'Other', \n",
    "        'Lady': 'Other', \n",
    "        'Sir': 'Other', \n",
    "        'Capt': 'Other', \n",
    "        'the Countess': 'Other', \n",
    "        'Jonkheer': 'Other',\n",
    "        'Dona': 'Other',\n",
    "    }).fillna(df['Pronouns'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Descrição**:\n",
    "A função `process_embarked` preenche valores nulos na coluna 'Embarked' de um DataFrame com o valor mais frequente e, em seguida, codifica os valores da coluna em valores numéricos.\n",
    "\n",
    "**Parâmetros**:\n",
    "- `df` (pd.DataFrame): O DataFrame contendo a coluna 'Embarked' que será processada.\n",
    "\n",
    "**Retorno**:\n",
    "- Retorna o DataFrame com a coluna 'Embarked' sem valores nulos e com os valores originais codificados em inteiros.\n",
    "\n",
    "**Funcionamento**:\n",
    "1. A função recebe um DataFrame (`df`) que contém a coluna 'Embarked'.\n",
    "2. Preenche os valores nulos na coluna 'Embarked' com o valor mais frequente (modo) da coluna.\n",
    "3. Utiliza `LabelEncoder` para transformar os valores categóricos da coluna 'Embarked' em valores numéricos.\n",
    "4. Retorna o DataFrame com a coluna 'Embarked' atualizada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_embarked(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df['Embarked'] = df['Embarked'].fillna(df['Embarked'].mode()[0])    \n",
    "    df.Embarked = LabelEncoder().fit_transform(df['Embarked'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Descrição**:\n",
    "A função `process_age` preenche valores nulos na coluna 'Age' de um DataFrame com a média das idades, calculada com base no sexo e na classe dos passageiros.\n",
    "\n",
    "**Parâmetros**:\n",
    "- `df` (pd.DataFrame): O DataFrame contendo a coluna 'Age' que será processada.\n",
    "\n",
    "**Retorno**:\n",
    "- Retorna o DataFrame com a coluna 'Age' sem valores nulos, onde os valores ausentes foram preenchidos com a média das idades para o mesmo sexo e classe.\n",
    "\n",
    "**Funcionamento**:\n",
    "1. A função recebe um DataFrame (`df`) que contém a coluna 'Age'.\n",
    "2. Utiliza o método `fillna` para preencher os valores nulos na coluna 'Age' com a média das idades dos passageiros que pertencem ao mesmo grupo de sexo (`Sex`) e classe (`Pclass`).\n",
    "3. O método `groupby` agrupa os dados por sexo e classe, e o método `transform('mean')` calcula a média da idade dentro de cada grupo.\n",
    "4. Retorna o DataFrame com a coluna 'Age' atualizada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_age(df: pd.DataFrame):\n",
    "    df['Age'] = df['Age'].fillna(df.groupby(by=['Sex', 'Pclass'])['Age'].transform('mean'))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Descrição**:\n",
    "A função `calcular_roc_auc` calcula a curva ROC e a área sob a curva (AUC) para um conjunto de valores verdadeiros e previstos.\n",
    "\n",
    "**Parâmetros**:\n",
    "- `y_true`: Lista ou array contendo os valores verdadeiros das classes.\n",
    "- `y_pred`: Lista ou array contendo as previsões do modelo.\n",
    "\n",
    "**Retorno**:\n",
    "- Retorna o valor da AUC (Área Sob a Curva ROC).\n",
    "\n",
    "**Funcionamento**:\n",
    "1. A função recebe dois parâmetros: `y_true` com os valores verdadeiros das classes e `y_pred` com as previsões do modelo.\n",
    "2. Utiliza a função `roc_curve` para calcular a curva ROC (taxa de falsos positivos `fpr` e taxa de verdadeiros positivos `tpr`).\n",
    "3. Calcula a área sob a curva (AUC) utilizando a função `auc` aplicada aos valores `fpr` e `tpr`.\n",
    "4. Retorna o valor calculado da AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_roc_auc(y_true, y_pred):\n",
    "    # Calcular a curva ROC\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
    "    \n",
    "    # Calcular a área sob a curva (AUC)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    return roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exibir_metricas_desempenho(ypred, ytrue):\n",
    "    acuracia = accuracy_score(y_pred=ypred, y_true=ytrue)\n",
    "    precisao = precision_score(y_pred=ypred, y_true=ytrue)\n",
    "    revocacao = recall_score(y_pred=ypred, y_true=ytrue)\n",
    "    roc_auc = calcular_roc_auc(y_pred=ypred, y_true=ytrue)\n",
    "\n",
    "    print(f'Acurácia: {round(acuracia, 5)}')\n",
    "    print(f'Precisão: {round(precisao, 5)}')\n",
    "    print(f'Revocação: {round(revocacao, 5)}')\n",
    "    print(f'ROC-AUC: {round(roc_auc, 5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_auc(ytrue, ypred):\n",
    "    # Gerar curva de precisão-revocação\n",
    "    precision, recall, _ = precision_recall_curve(ytrue, ypred)\n",
    "\n",
    "    plt.figure(figsize=(14, 7))\n",
    "\n",
    "    # Subplot para a curva de precisão-revocação\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(recall, precision, marker='.', label='Precision-Recall Curve')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.legend()\n",
    "\n",
    "    # Subplot para a curva ROC\n",
    "    fpr, tpr, _ = roc_curve(ytrue, ypred)\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(fpr, tpr, marker='.', label='ROC Curve')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend()\n",
    "\n",
    "    # Mostrar os gráficos\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\">OBTENHA E PROCESSE OS DADOS</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obter_dataframe_processado(path: str):\n",
    "    df = carregar_dados(path=path)\n",
    "    df = process_age(df=df)\n",
    "    df = adicionar_indicador_menor_idade(df)\n",
    "    df = transformar_sex_em_inteiro(df)\n",
    "    df['Pronouns'] = df.Name.map(get_pronouns)\n",
    "    df = join_pronouns(df)\n",
    "    df = encoding_pronouns(df=df)\n",
    "    df = process_embarked(df=df)\n",
    "    df['Fare'] = df['Fare'].fillna(df['Fare'].mean())\n",
    "    return df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenha o dataframe utilizando o método ``obter_dataframe_processado()`` e visualize as transformações com a função head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span id=\"id_secao_prevendo_sobreviventes\" style=\"color:green\">SEPARE OS DADOS DE TREINO E TESTE</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reutilize o método `obter_treino_e_teste()` para dividir o dataframe em treino e teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino, teste = obter_treino_e_teste()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_predict = ['Pclass', 'Fare', 'SibSp', 'Parch', 'Sex', 'isChild', 'Embarked', 'Age', 'Pronouns']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crie x_treino, y_treino, x_teste e y_teste utilizando os dataframes de trino e teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_treino = \n",
    "y_treino = \n",
    "\n",
    "x_teste = \n",
    "y_teste = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span id=\"id_secao_prevendo_sobreviventes\" style=\"color:green\">AVALIE DIVERSOS MODELOS EM VALIDAÇÃO CRUZADA</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crie um array de tuplas para armazenar os modelos que serão processados em validação cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Razões para Padronizar Dados em Modelos de Machine Learning\n",
    "\n",
    "1. **Consistência de Escala**\n",
    "Padronizar dados garante que todas as variáveis estejam na mesma escala, o que é crucial para algoritmos de Machine Learning que dependem da distância entre pontos de dados, como ***regressão linear e k-vizinhos mais próximos***.\n",
    "\n",
    "2. **Melhoria na Convergência**\n",
    "Algoritmos de otimização, como gradiente descendente, convergem mais rápido e com mais eficiência quando os dados são padronizados.\n",
    "\n",
    "3. **Redução de Vieses**\n",
    "A padronização ajuda a reduzir vieses que podem surgir devido a diferenças de escala, permitindo que o modelo trate todas as variáveis de forma justa.\n",
    "\n",
    "4. **Melhor Desempenho de Modelos**\n",
    "Modelos como Support Vector Machines ***(SVM) e Redes Neurais*** beneficiam-se da padronização dos dados, levando a um desempenho superior e resultados mais precisos.\n",
    "\n",
    "Conclusão\n",
    "Padronizar dados é um passo fundamental no pré-processamento de dados para Machine Learning, garantindo a consistência e eficácia dos modelos treinados. Certifique-se de incluir esse passo no seu pipeline de dados para obter melhores resultados nos seus projetos de Machine Learning.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crie um array de tuplas no formato ('aliasModelo', modelo), para armazenar modelos que tem melhora no desempenho se receber dados padronizados no processo de treinamento e teste. Inicialmente, utilizaremos os modelos ***XGBClassifier, LogisticRegression, SGDClassifier, KNeighborsClassifier***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelos que precisam de padronização\n",
    "scaled_models = [\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faça o mesmo com os modelos ***GradientBoostingClassifier, LGBMClassifier, RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier, HistGradientBoostingClassifier, RidgeClassifier, DecisionTreeClassifier***. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelos sem necessidade de padronização\n",
    "non_scaled_models = [\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Descrição**:\n",
    "O código aplica o `StandardScaler` apenas aos modelos que são sensíveis à escala dos dados, utilizando um pipeline que sequencia a padronização dos dados seguida pelo treinamento do modelo.\n",
    "\n",
    "**Funcionamento do Código**:\n",
    "\n",
    "1. **Definição dos Modelos Sensíveis à Escala**:\n",
    "    - Os modelos são definidos em uma lista chamada `scaled_models`, onde cada elemento é uma tupla que contém o nome do modelo e a instância do modelo. Estes modelos são conhecidos por se beneficiarem da padronização dos dados.\n",
    "\n",
    "2. **Criação do Pipeline**:\n",
    "    - Utiliza-se uma compreensão de lista para iterar sobre cada tupla na lista `scaled_models`.\n",
    "    - Para cada tupla (nome, modelo), cria-se um `Pipeline` do `scikit-learn` que consiste em dois estágios:\n",
    "        1. `'scaler'`: Aplica o `StandardScaler` para padronizar os dados.\n",
    "        2. `'classifier'`: Aplica o modelo de classificação.\n",
    "    - O `Pipeline` é então empacotado novamente em uma tupla contendo o nome do modelo e o pipeline completo.\n",
    "\n",
    "3. **Lista de Pipelines**:\n",
    "    - A lista `pipelines` resultante contém todas as tuplas de (nome, pipeline) para os modelos sensíveis à escala."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crie e aplique um pipeline sobre os models sensíveis à escala (scaled_models). \n",
    "\n",
    "Mas o que é um **pipeline**? Um pipeline é uma ferramenta poderosa que permite concatenar várias etapas de processamento de dados e modelagem em uma única sequência."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando o Pipeline com StandardScaler apenas aos modelos sensíveis à escala\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models = non_scaled_models + pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Descrição**:\n",
    "A função `avaliar_modelos` realiza a validação cruzada em diversos modelos de Machine Learning e retorna a média e o desvio padrão das pontuações de precisão.\n",
    "\n",
    "**Parâmetros**:\n",
    "- `modelos`: Uma lista de tuplas contendo o nome do modelo e a instância do modelo.\n",
    "- `X`: O DataFrame contendo as características (features) do dataset.\n",
    "- `y`: A série ou DataFrame contendo os rótulos (labels) do dataset.\n",
    "- `n_splits` (int, opcional): Número de folds para a validação cruzada (padrão é 10).\n",
    "- `metric` (str, opcional): Métrica de avaliação dos modelos (padrão é 'accuracy').\n",
    "\n",
    "**Retorno**:\n",
    "- Retorna um dicionário `resultados` onde as chaves são os nomes dos modelos e os valores são dicionários contendo a média e o desvio padrão das pontuações de precisão.\n",
    "\n",
    "**Funcionamento**:\n",
    "1. A função inicializa um dicionário `resultados` para armazenar os resultados de cada modelo.\n",
    "2. Utiliza `KFold` do `sklearn` para dividir o dataset em `n_splits` folds, com embaralhamento dos dados e uma semente aleatória para reprodutibilidade.\n",
    "3. Itera sobre cada modelo na lista `modelos`:\n",
    "    - Para cada modelo, inicializa uma lista `scores` para armazenar as pontuações de cada fold.\n",
    "    - Realiza a validação cruzada sem estratificação:\n",
    "        - Divide os dados de treinamento e teste para cada fold.\n",
    "        - Treina o modelo com os dados de treinamento.\n",
    "        - Prediz os rótulos para os dados de teste.\n",
    "        - Calcula e armazena a pontuação de precisão para o fold atual.\n",
    "    - Calcula a média e o desvio padrão das pontuações de precisão e armazena no dicionário `resultados` com o nome do modelo como chave.\n",
    "4. Retorna o dicionário `resultados`.\n",
    "\n",
    "**Exemplo de Uso**:\n",
    "```python\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "modelos = [\n",
    "    ('Random Forest', RandomForestClassifier()),\n",
    "    ('Logistic Regression', LogisticRegression())\n",
    "]\n",
    "\n",
    "resultados = avaliar_modelos(modelos, X, y)\n",
    "print(resultados)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crie uma função para avaliar modelos em validação cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def avaliar_modelos(modelos, X, y, n_splits=10, metric='accuracy'):\n",
    "    resultados = {}\n",
    "    \n",
    "    # Divide a base de dados em 10 folds. \n",
    "    kf = KFold()\n",
    "    \n",
    "    for nome, modelo in modelos:\n",
    "        scores = []\n",
    "        \n",
    "        # Realizar a validação cruzada sem estratificação\n",
    "        for train_idx, test_idx in kf.split(X):\n",
    "            X_train, X_test = \n",
    "            y_train, y_test = \n",
    "            \n",
    "            modelo.fit()\n",
    "            y_pred = modelo.predict()\n",
    "            scores.append(accuracy_score())\n",
    "        \n",
    "        resultados[nome] = {\n",
    "            'media': ,\n",
    "            'desvio_padrao': \n",
    "        }\n",
    "    \n",
    "    return resultados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize o desempenho dos modelos percorrendo o dicionário de resultados devolvidos pela função ``avaliar_modelos()``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = avaliar_modelos()\n",
    "\n",
    "for nome, resultado in resultados.items():\n",
    "    print(f\"{nome}: Média = {resultado['media']:.5f}, Desvio Padrão = {resultado['desvio_padrao']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\">COMBINE DIVERSOS MODELOS EM UM ENSAMBLE E FAA PREVISÕES</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o StackingClassifier\n",
    "stacking_model = StackingClassifier(\n",
    "    estimators= ,\n",
    "    final_estimator= ,  # Meta-aprendiz (pode ser ajustado)\n",
    "    passthrough= ,  # Se True, inclui as features originais junto com as previsões na meta-aprendizagem\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Exemplo de treinamento\n",
    "stacking_model.fit()\n",
    "y_pred = stacking_model.predict()\n",
    "accuracy_score()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
